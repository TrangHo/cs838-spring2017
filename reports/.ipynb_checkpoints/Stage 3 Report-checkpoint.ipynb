{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS 838 &mdash; Data Science: Principles, Algorithms, and Applications; Spring 2017 ###\n",
    "\n",
    "#  Stage 3: entity matching #\n",
    "\n",
    "#### Trang Ho, Thomas Ngo, Qinyuan Sun\n",
    "\n",
    "*****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction ##\n",
    "\n",
    "In this project stage, our team performed matching entities between two tables of education affiliations. The first table was extracted from the Academy of Management Conference (AOM) website, which contains personal information of the conference attendants in the year 2014. The personal information includes (1) individual name, (2) affiliation name, (3) country, (4) states/ province, (5) city, (6) contact numbers, (7) email address. Overall, this table consists of 9,532 entities at the individual level. \n",
    "\n",
    "The second table was extracted from the World Higher Education Database (WHED), which contains information of unique education affiliations worldwide. This table provides information on (1) affiliation name, (2) country, (3) street, (4) city, (5) province/ states, (6) postal code, (7) telephone number, and (8) website address (if available). Overall, this table consists of 17,605 unique entities at the affiliation level.\n",
    "\n",
    "In order to match individuals' affiliations on the first table to affiliations on the second table, we used their overlapped/relevant information: (1) affiliation name, (2) country, (3) province/states, (4) city, (5) website address, (6) individual email address. Our goal here is to get precision score of above 95% and recall score of as high as possible.\n",
    "\n",
    "Subsequently, we carried out the following steps using Magellan:\n",
    "* Pre-processing\n",
    "* Down-sizing the AOM table and the WHED table\n",
    "* Using a blocker to reduce the size of the potential-candidate set\n",
    "* Sampling randomly 500 pairs of potential candidates for labelling\n",
    "* Creating training and testing sets I and J\n",
    "* Training and selecting the best classifier using cross-validation\n",
    "* Evaluating performance on the testing set J\n",
    "\n",
    "More details can be found below.\n",
    "\n",
    "## 2. Matching procedure ##\n",
    "\n",
    "### Step 1. Pre-processing\n",
    "In this step, we cleaned the two datasets by standardizing information on affiliation names, country, state/province, city, email server domain. For example, we standardized states by transforming \"CA\", \"CA - California\", \"California\" to \"california\" on both the AOM table and the WHED data.\n",
    "\n",
    "### Step 2. Down-sizing\n",
    "Initially, we have 9,532 entities on the AOM table and 17,605 entities on the WHED data. After down-sizing, we have 4,000 AOM entities and 4962 WHED entities\n",
    "\n",
    "### Step 3. Blocking\n",
    "Our blocking consists of the following components:\n",
    "* Blocking all tuple pairs that have different countries\n",
    "* For American affiliations, blocking all tuple pairs that have different province/ states\n",
    "* For all affiliations, blocking all tuple pairs that have neither (1) any overlap between AOM email domain and WHED affiliation website domain nor (2) sufficient overlap coefficient (i.e. greater than 0.5) between affiliation names\n",
    "\n",
    "As a result, we reduced the size of our candidate set from 19,848,000 (=4,000 x 4,962) to 126,516. \n",
    "\n",
    "### Step 4. Sampling for labelling\n",
    "We initially sampled randomly 500 tuple pairs from the set of 126,516 potential candidates. After labeling, we dropped 22 cases due to ambiguity of the AOM information. Consequently, we had 478 tuple pairs with a density of approximately 34%.\n",
    "\n",
    "### Step 5. Creating training & testing sets\n",
    "We split the sample set into training and testing sets. As a result, each set has 239 tuple pairs.\n",
    "\n",
    "|                | Num. of entities | Num. of positive examples  | Num. of negative examples|\n",
    "| -------------  |:----------------:| :-------------:            | :-------------:          |\n",
    "| Training Set I | 239              |     81 (33.8%)             |  158 (66.2%)             |\n",
    "| Testing Set J  | 239              |     73 (30.5%)             |  166 (69.5%)             |\n",
    "| Total          | 478              |     154                    |  324                     |\n",
    "\n",
    "\n",
    "### Step 6. Training and selecting the best classifiers\n",
    "We used 6 learning methods for training on set I using 5-fold cross validation. The methods include: (1) Decision Tree, (2) Random Forest, (3) SVM, (4) Naive Bayes, (5) Logistic Regression, and (6) Linear Regression. Our classifiers use 34 features, and below is the first-attempt accuracy performance of our classifiers on the training set I:\n",
    "\n",
    "| Machine Learning Algorithm| Avg. CV Precision| Avg. CV Recall |     F1    |\n",
    "| ------------------------- |:----------------:| :-------------:|:---------:|\n",
    "| Decsion Tree              | 0.88             |     0.87       | 0.87      | \n",
    "| Random Forest             | 0.95             |     0.90       | 0.92      | \n",
    "| Support Vector Machine    | 0.96             |     0.51       | 0.63      |\n",
    "| Naive Bayes               | 0.96             |     0.51       | 0.63      | \n",
    "| Logistic Regression       | 0.89             |     0.89       | 0.88      | \n",
    "| Linear Regression         | 0.93             |     0.84       | 0.88      | \n",
    "\n",
    "\n",
    "For its simplicity and accuracy performance, we selected the Random Forest learning method for our testing.\n",
    "\n",
    "### Step 7. Evaluating performance\n",
    "\n",
    "We trained the classifier with all the training examples and tested on the testing examples. The results are shown in the following table. \n",
    "\n",
    "|Type  |Precision| Recall |F1  |\n",
    "| ---- |:-------:|:------:|:--:|\n",
    "|TRAIN |1.00     | 0.98   |0.99|\n",
    "|TEST  |0.99     | 0.91   |0.95|\n",
    "\n",
    "## 3. Links ##\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/texts) to 300 text document\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/train-texts) to training set\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/test-examples) to test set\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/src) to source code\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-spring2017/raw/master/cs838-stage2.zip) to a zip file for stage 2 related documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
